<analysis>
**original_problem_statement:**
The user wants to build a full-stack application, Cerebro Visas, to manage and analyze US immigration visa cases. The core goal is to upload case documents, use LLMs for data extraction and analysis, and provide AI-powered tools to improve case preparation and approval rates.

During the session, the user's requests expanded to include:
- A Drift Detector to identify new trends in USCIS requests (RFE/NOID).
- A Claim Graph to visually map case arguments to supporting evidence and score their strength.
- A Robustness Score to provide a top-level KPI for case readiness.
- A feature to import an entire client case by providing a Google Drive folder link.
- An alternative feature to import a case by uploading a .zip file.
- The ability to exclude specific folders/files during the import process.

PRODUCT REQUIREMENTS:
- **Capa A - Ingesta y normalización:** Document upload (individual, bulk, Drive, ZIP) and text/OCR extraction.
- **Capa B - Extracción estructurada:** An LLM Case Miner for structured data extraction, including a detailed  of issues.
- **Capa C - Memoria dual:** Storing data in a SQL database (Supabase) and a vector database () for semantic search, now with page-level citations.
- **Capa D - Inteligencia de tendencias:** Dashboards for trends, a Drift Detector, and Issue Frequency Engine.
- **Capa E - Chat + Auditor:** A RAG-based chat that can cite sources by page number, a case audit tool (the Claim Graph), and a Prompt Analyzer.

**User's preferred language**: Spanish (español).

**what currently exists?**
A feature-rich Next.js 14 application with Supabase. The backend for bulk document uploads is now fixed and tested. Several major new features have been added:

- **Drift Detector & Issue Frequency Engine:** A new page () and corresponding APIs (, ) have been created. They analyze document issues over time to detect new patterns and rank the most common problems. The UI successfully displays these alerts and frequency charts.
- **Page-Level Citations:** The entire document processing and RAG pipeline has been upgraded. Text is extracted per-page, embeddings store page references, and the chat API now provides context with page numbers, which are displayed in the UI as sources.
- **Intelligent Bulk Upload:** The bulk upload backend () has been significantly improved. It now automatically detects the document type (RFE, NOID, etc.) from the filename and selectively generates embeddings only for relevant analysis documents.
- **Claim Graph (Foundation):** The foundational backend is in place. SQL tables (, ) and a powerful API () have been created to extract claims, link evidence, and calculate strength scores using an LLM. A UI page () has been created with buttons to trigger this analysis.
- **Google Drive / ZIP Import (In Progress):** A new UI () and backend APIs (, ) have been created to allow importing a full case from a Google Drive folder or a ZIP file. This feature includes logic for progress bars (using Server-Sent Events) and excluding specific folders from the import.

**Last working item**:
-   **Last item agent was working:** Implementing the UI for the Drive/ZIP import feature. Specifically, the agent was adding functionality to the  component to allow the user to click on folders to exclude them and their contents from the import process.
-   **Status:** IN PROGRESS
-   **Agent Testing Done:** N
-   **User Testing Done:** N
-   **Which testing method agent to use?** Frontend testing agent. The agent should navigate to the  page and test both the ZIP upload and Google Drive URL flows. The test should verify that:
    1.  After providing a ZIP file or Drive URL, a file/folder tree is displayed.
    2.  Clicking a folder marks it (and its files) as excluded visually.
    3.  The final import process respects these exclusions.
    4.  The progress bar updates correctly during the import.

**All Pending/In progress Issue list**:
-   Issue 1: The Drive/ZIP import feature is in a partially implemented state and may contain bugs. (P0 - HIGHEST)
-   Issue 2: Newly created SQL schemas have not been applied to the database. (P0 - CRITICAL BLOCKER)
-   Issue 3: The Claim Graph feature is untested end-to-end. (P1)
-   Issue 4: User authentication is broken for new signups. (P1)
-   Issue 5: The bulk document upload UI has never been tested. (P2)

**Issues Detail:**
-   **Issue 1: Drive/ZIP Import feature is unstable.**
    -   **Description**: The user reported a 403 error (API not enabled) and a 500 error (likely from recursive calls) with the Google Drive import. The agent pivoted to add retries, SSE for progress, and then started adding a ZIP import alternative and folder exclusion logic. The feature is complex and was left mid-development.
    -   **Attempted fixes**: Added retries and delays to the Google Drive API calls. Started implementing Server-Sent Events for progress.
    -   **Next debug checklist**:
        1.  First, ensure Issue #2 is resolved by running the SQL migrations.
        2.  Test the ZIP import flow, as it's simpler and has no external dependencies.
        3.  Test the Drive import flow. Confirm with the user that the Google Drive API has been enabled in their Google Cloud project.
        4.  Verify that the progress bar works and that the folder exclusion logic correctly prevents files from being processed.
    -   **Why fix this issue and what will be achieved with the fix?**: This is a major feature requested by the user to streamline client onboarding. Fixing it will provide a massive improvement to the application's workflow.
    -   **Status**: IN PROGRESS
    -   **Is recurring issue?**: Y
    -   **Should Test frontend/backend/both after fix?**: both
    -   **Blocked on other issue**: Issue 2

-   **Issue 2: SQL migrations have not been run.**
    -   **Description**: The agent created  and  but never executed them. These files create critical tables for the Drift Detector, Claim Graph, and Page-Level Citations. All features built in this session will fail without these DB changes.
    -   **Attempted fixes**: N/A.
    -   **Next debug checklist**:
        1.  Open the Supabase SQL Editor.
        2.  Execute the entire content of .
        3.  Execute the entire content of .
    -   **Why fix this issue and what will be achieved with the fix?**: This will fix the database schema, unblocking almost all other new features and allowing them to be tested. **This is a prerequisite for all other tasks.**
    -   **Status**: NOT STARTED
    -   **Is recurring issue?**: N
    -   **Should Test frontend/backend/both after fix?**: backend
    -   **Blocked on other issue**: None

-   **Issue 3: The Claim Graph feature is untested.**
    -   **Description**: The agent built the UI page, backend API, and LLM prompts for extracting claims and analyzing evidence. However, the full end-to-end flow (navigating to the page, clicking Extract Claims, seeing results) has not been tested.
    -   **Status**: NOT STARTED
    -   **Should Test frontend/backend/both after fix?**: both
    -   **Blocked on other issue**: Issue 2

-   **Issue 4: User authentication is broken for new signups.**
    -   **Description**: The agent discovered that new users who sign up are required to verify their email. In the test environment, this is not possible, blocking them from logging in. The agent bypassed this by using an existing user or making pages public, but the root cause for new user onboarding remains.
    -   **Status**: NOT STARTED
    -   **Should Test frontend/backend/both after fix?**: backend
    -   **Blocked on other issue**: None

**In progress Task List**:
-   **Task 1: Complete and Stabilize Drive/ZIP Import Feature (P0)**
    -   **Where to resume**: Review  and . The immediate goal is to finalize the UI logic for excluding folders and ensure the backend processing respects the user's selections.
    -   **What will be achieved with this?**: A robust, user-friendly way to ingest entire client cases at once.
    -   **Status**: IN PROGRESS
    -   **Should Test frontend/backend/both after fix?**: both
    -   **Blocked on something**: Issue 2: SQL migrations must be run first.

**Upcoming and Future Tasks**
-   **(P1) Implement Cohort Analyzer by Industry**: Add an  field to cases and modify the Cohort Analyzer to allow grouping by this new field.
-   **(P1) Add Visual Graph to Claim Graph**: Enhance the  page with an interactive graph visualization (e.g., using D3.js or a similar library) to show relationships between claims and evidence.
-   **(P2) Export Auditor Report to PDF**: Add a feature to export the Auditor de Expediente report to a PDF.
-   **(P2) Improve Prompt History UI**: Enhance the UI to more clearly show the status of each entry.

**Completed work in this session**
- **Fixed Bulk Upload Backend**: Resolved a critical crash and multiple schema-related bugs. The backend at  is now robust and tested via curl.
- **Implemented Intelligent Embeddings**: The bulk upload process now auto-detects document types from filenames and only generates embeddings for analysis-heavy documents (, , ).
- **Implemented Page-Level Citations**: The entire RAG pipeline (processing, storage, API, UI) was upgraded to support and display page number citations for sources.
- **Implemented Drift Detector**: Created database tables, a backend API, and a new UI page () to show emerging trends in document issues.
- **Implemented Issue Frequency Engine**: Created a backend API and integrated it into the Drift Detector UI to show a ranked list of the most common issues.
- **Implemented Claim Graph Foundation**: Created the database schema, a powerful backend API for LLM-based claim/evidence analysis, and the initial UI page.
- **Dashboard Integration**: Added links to all new features (Drift Detector, Drive Import) on the main dashboard.
- **Started Drive/ZIP Import Feature**: Created the initial UI and backend APIs for both import methods, including logic for progress bars and folder exclusion.

**Earlier issues found/mentioned but not fixed**
-   **Issue 1: Supabase Email Verification for New Users**
    -   **Debug checklist**:
        1.  Navigate to the Supabase project settings.
        2.  Go to the Authentication -> Providers section.
        3.  Find the Email provider settings.
        4.  Disable the Confirm email toggle.
        5.  This will allow new users to log in immediately after signing up, which is suitable for a development environment.
    -   **Why to solve this issue and what will be achieved with this?**: This will fix the user onboarding flow and allow for proper end-to-end testing of features that require authentication, without needing workarounds.
    -   **Should Test frontend/backend/both after fix**: backend
    -   **Is recurring issue?**: Y

**Code Architecture**


**Key Technical Concepts**
- **Framework:** Next.js 14 (App Router)
- **Database:** Supabase (PostgreSQL) with **pgvector**.
- **AI/LLM:** OpenRouter for various models ().
- **File Processing:**  for PDF text extraction (now page-aware), **** for ZIP file handling.
- **Real-time UI:** **Server-Sent Events (SSE)** for live progress bars during imports.
- **External APIs:** **Google Drive API**.

**key DB schema**
- : (MODIFIED) Added  (text) to store the page number of the text chunk.
- : (NEW) { case_id, claim_text, prong_mapping, evidence_strength_score, status }
- : (NEW) { claim_id, evidence_doc_id, strength_score, rationale, gaps_identified }
- : (NEW) { taxonomy_code, alert_type, change_pct, severity }
- : (NEW) { cohort_type, cohort_value, period_start, rfe_rate, top_issues }

**All files of reference**
-   : **CRITICAL**. Contains schema for new P0 features. Must be executed.
-   : **CRITICAL**. Adds page reference column. Must be executed.
-   : The UI for the in-progress import feature.
-   : The backend for the in-progress import feature.
-   : The new, untested UI for the Claim Graph.
-   : The new, untested API for the Claim Graph.
-   : The UI for the new, working Drift Detector feature.
-   : The fixed and improved backend for bulk uploads.

**Critical Info for New Agent**
-   **IMMEDIATE ACTION REQUIRED**: You **MUST** run the SQL files  and  in the Supabase SQL Editor. The majority of the new features built in the last session depend on these database schema changes and will fail without them.
-   **TOP PRIORITY**: Your first development task is to stabilize and complete the Drive/ZIP import feature, which was left in a half-finished state. Start by testing the simpler ZIP import flow, then move to the Google Drive flow.
-   **AUTH IS BROKEN**: New user signup is broken due to a required email verification step in Supabase. For testing, you can either use the existing user  (if sessions persist) or disable email confirmation in the Supabase project settings.
-   **TEST NEW FEATURES**: After running the SQL migrations, the Claim Graph () and Drift Detector () are ready for end-to-end testing.

**Last 10 User Messages and any pending HUMAN messages**
10. Asks for a way to import from a Google Drive folder. (IN PROGRESS)
9.  Provides details for the Drive import: use sub-folders, handle many files. (IN PROGRESS)
8.  Provides the Google Drive API Key. (DONE)
7.  Shows a screenshot of a 403 error from the Drive import. (ADDRESSED, needs user to enable API).
6.  Reports a 500 error and asks for a progress bar for the Drive import. (IN PROGRESS)
5.  Suggests using a .zip file upload as an alternative to Google Drive. (IN PROGRESS)
4.  Asks to be able to exclude folders from the import process. (IN PROGRESS)
3.  Asks to start work on the Claim Graph. (DONE)
2.  Asks to implement Citas con página/párrafo. (DONE)
1.  Asks for an explanation of which partially implemented features are most important. (DONE)

**Project Health Check:**
-   **Broken**:
    -   The Google Drive / ZIP import feature is mid-development and not functional.
    -   The database schema is out of sync with the code, breaking all new features.
    -   The authentication flow for new users is broken due to email verification.
-   **Mocked**: None.

**3rd Party Integrations**
-   **Supabase**: For database, auth, storage, and . Requires user-provided keys.
-   **OpenRouter**: For all LLM and embedding model access. Uses an API Key from environment variables.
-   **Google Drive API**: To list and download files from a user's Google Drive. Requires a user-provided API key, which has been added to .
-   **adm-zip**: A new npm <command>

Usage:

npm install        install all the dependencies in your project
npm install <foo>  add the <foo> dependency to your project
npm test           run this project's tests
npm run <foo>      run the script named <foo>
npm <command> -h   quick help on <command>
npm -l             display usage info for all commands
npm help <term>    search for help on <term>
npm help npm       more involved overview

All commands:

    access, adduser, audit, bugs, cache, ci, completion,
    config, dedupe, deprecate, diff, dist-tag, docs, doctor,
    edit, exec, explain, explore, find-dupes, fund, get, help,
    help-search, hook, init, install, install-ci-test,
    install-test, link, ll, login, logout, ls, org, outdated,
    owner, pack, ping, pkg, prefix, profile, prune, publish,
    query, rebuild, repo, restart, root, run-script, sbom,
    search, set, shrinkwrap, star, stars, start, stop, team,
    test, token, uninstall, unpublish, unstar, update, version,
    view, whoami

Specify configs in the ini-formatted file:
    /root/.npmrc
or on the command line via: npm <command> --key=value

More configuration info: npm help config
Configuration fields: npm help 7 config

npm@10.8.2 /usr/lib/node_modules/npm dependency for handling .zip files on the backend.
-   **react-markdown**: Used for rendering chat responses.

**Testing status**
-   Testing agent used after significant changes: NO
-   Troubleshoot agent used after agent stuck in loop: NO
-   Test files created: None.
-   Known regressions: New user signup is effectively broken.

**Credentials to test flow:**
-   An active user session for  may exist.
-   A new user  was created, but cannot log in due to required email verification.
-   Google Drive API key is present in  as .

**What agent forgot to execute**
-   The agent created two critical SQL migration files ( and ) but **never ran them on the database**. This is a critical oversight that will cause the Drift Detector, Claim Graph, and page-level citation features to fail. This must be the very first action taken.
</analysis>
